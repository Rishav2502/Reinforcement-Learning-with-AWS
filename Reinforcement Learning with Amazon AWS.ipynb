{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e68f45e",
   "metadata": {},
   "source": [
    "# AWS REINFORCEMENT LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37323b10",
   "metadata": {},
   "source": [
    "Glossary:\n",
    "    Terms to know before starting to it:\n",
    "\n",
    "Bag of words: A technique used to extract features from the text. It counts how many times a word               appears in a document (corpus), and then transforms that information into a                       dataset.\n",
    "\n",
    "A categorical label has a discrete set of possible values, such as \"is a cat\" and \"is not a cat.\"\n",
    "\n",
    "Clustering: Unsupervised learning task that helps to determine if there are any naturally                     occurring groupings in the data.\n",
    "\n",
    "CNN: Convolutional Neural Networks (CNN) represent nested filters over grid-organized data. They      are by far the most commonly used type of model when processing images.\n",
    "\n",
    "A continuous (regression) label does not have a discrete set of possible values, which means possibly an unlimited number of possibilities.\n",
    "\n",
    "Data vectorization: A process that converts non-numeric data into a numerical format so that it                       can be used by a machine learning model.\n",
    "\n",
    "Discrete: A term taken from statistics referring to an outcome taking on only a finite number of           values (such as days of the week).\n",
    "\n",
    "FFNN: The most straightforward way of structuring a neural network, the Feed Forward Neural              Network (FFNN) structures neurons in a series of layers, with each neuron in a layer              containing weights to all neurons in the previous layer.\n",
    "\n",
    "Hyperparameters: They are settings on the model which are not changed during training but can                      affect how quickly or how reliably the model trains, such as the number of                        clusters the model should identify.\n",
    "\n",
    "Log loss is used to calculate how uncertain your model is about the predictions it is generating.\n",
    "\n",
    "Hyperplane: A mathematical term for a surface that contains more than two planes.\n",
    "\n",
    "Impute is a common term referring to different statistical tools which can be used to calculate missing values from your dataset.\n",
    "\n",
    "label refers to data that already contains the solution.\n",
    "\n",
    "loss function is used to codify the model’s distance from this goal\n",
    "\n",
    "Machine learning, or ML, is a modern software development technique that enables computers to solve problems by using examples of real-world data.\n",
    "\n",
    "Model accuracy is the fraction of predictions a model gets right. \n",
    "\n",
    "Discrete: A term taken from statistics referring to an outcome taking on only a finite number of           values (such as days of the week). \n",
    "\n",
    "Continuous: Floating-point values with an infinite range of possible values. The opposite of                 categorical or discrete values, which take on a limited number of possible values.\n",
    "\n",
    "Model inference is when the trained model is used to generate predictions.\n",
    "\n",
    "model is an extremely generic program, made specific by the data used to train it.\n",
    "\n",
    "Model parameters are settings or configurations the training algorithm can update to change how the model behaves.\n",
    "\n",
    "Model training algorithms work through an interactive process where the current model iteration is analyzed to determine what changes can be made to get closer to the goal. Those changes are made and the iteration continues until the model is evaluated to meet the goals.\n",
    "\n",
    "Neural networks: a collection of very simple models connected together. These simple models are                    called neurons. The connections between these models are trainable model                          parameters called weights.\n",
    "\n",
    "Outliers are data points that are significantly different from others in the same sample.\n",
    "\n",
    "Plane: A mathematical term for a flat surface (like a piece of paper) on which two points can be        joined by a straight line.\n",
    "\n",
    "Regression: A common task in supervised machine learning.\n",
    "\n",
    "Reinforcement learning: In this the algorithm figures out which actions to take in a situation to                         maximize a reward (in the form of a number) on the way to reaching a                             specific goal.\n",
    "\n",
    "RNN/LSTM: Recurrent Neural Networks (RNN) and the related Long Short-Term Memory (LSTM) model               types are structured to effectively represent for loops in traditional computing,                 collecting state while iterating over some object. They can be used for processing               sequences of data.\n",
    "\n",
    "Silhouette coefficient: A score from -1 to 1 describing the clusters found during modeling. A                             score near zero indicates overlapping clusters, and scores less than zero                         indicate data points assigned to incorrect clusters.\n",
    "\n",
    "Stop words: A list of words removed by natural language processing tools when building your                   dataset. There is no single universal list of stop words used by all-natural language             processing tools.\n",
    "\n",
    "Supervised learning: In every training sample from the dataset has a corresponding label or                            output value associated with it. As a result, the algorithm learns to                            predict labels or output values.\n",
    "\n",
    "Test dataset: The data withheld from the model during training, which is used to test how well                 your model will generalize to new data.\n",
    "\n",
    "Training dataset: The data on which the model will be trained. Most of your data will be here.\n",
    "\n",
    "Transformer: A more modern replacement for RNN/LSTMs, the transformer architecture enables                    training over larger datasets involving sequences of data.\n",
    "\n",
    "Unlabeled data: In this you don't need to provide the model with any kind of label or solution                    while the model is being trained.\n",
    "\n",
    "In unsupervised learning, there are no labels for the training data. A machine learning algorithm tries to learn the underlying patterns or distributions that govern the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fb7bc",
   "metadata": {},
   "source": [
    "## 1. Reinforcement Learning and Its Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f5860",
   "metadata": {},
   "source": [
    "In reinforcement learning (RL), an agent is trained to achieve a goal based on the feedback it receives as it interacts with an environment. It collects a number as a reward for each action it takes. Actions that help the agent achieve its goal are incentivized with higher numbers. Unhelpful actions result in a low reward or no reward.\n",
    "With a learning objective of maximizing total cumulative reward, over time, the agent learns, through trial and error, to map gainful actions to situations. The better trained the agent, the more efficiently it chooses actions that accomplish its goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3653b41",
   "metadata": {},
   "source": [
    "### 1.1 Reinforcement Learning Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dfef36",
   "metadata": {},
   "source": [
    "RL is great at playing games:\n",
    "\n",
    "a)Go (board game) was mastered by the AlphaGo Zero software.\n",
    "   Atari classic video games are commonly used as a learning tool for creating and testing RL             software.\n",
    "   StarCraft II, the real-time strategy video game, was mastered by the AlphaStar software.\n",
    "   \n",
    "b)RL is used in video game level design:\n",
    "     Video game level design determines how complex each stage of a game is and directly affects          how boring, frustrating, or fun it is to play that game.\n",
    "    Video game companies create an agent that plays the game over and over again to collect data        that can be visualized on graphs.\n",
    "    This visual data gives designers a quick way to assess how easy or difficult it is for a            player to make progress, which enables them to find that “just right” balance between            boredom and frustration faster.\n",
    "    \n",
    "c)RL is used in wind energy optimization:\n",
    "    RL models can also be used to power robotics in physical devices.\n",
    "        When multiple turbines work together in a wind farm, the turbines in the front, which             receive the wind first, can cause poor wind conditions for the turbines behind them. This         is called wake turbulence and it reduces the amount of energy that is captured and               converted into electrical power.\n",
    "        \n",
    "d)Wind energy organizations around the world use reinforcement learning to test solutions. Their        models respond to changing wind conditions by changing the angle of the turbine blades.          When the upstream turbines slow down it helps the downstream turbines capture more energy.\n",
    "\n",
    "e)Other examples of real-world RL include:\n",
    "    -Industrial robotics\n",
    "    -Fraud detection\n",
    "    -Stock trading\n",
    "    -Autonomous driving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e3b1bc",
   "metadata": {},
   "source": [
    "### New terms in AWS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18084af",
   "metadata": {},
   "source": [
    "a)Agent: The piece of software you are training is called an agent. It makes decisions in an              environment to reach a goal.\n",
    "\n",
    "b)Environment: The environment is the surrounding area with which the agent interacts.\n",
    "\n",
    "c)Reward: Feedback is given to an agent for each action it takes in a given state. This feedback           is a numerical reward.\n",
    "\n",
    "d)Action: For every state, an agent needs to take an action toward achieving its goal.\n",
    "\n",
    "In a reinforcement learning model, an agent learns in an interactive real-time environment by trial and error using feedback from its own actions. Feedback is given in the form of rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dde924",
   "metadata": {},
   "source": [
    "e)Training Algorithm:The training algorithm defines your model’s learning objective, which is to                      maximize total cumulative reward. Different algorithms have different                            strategies for going about this.\n",
    "\n",
    "                         -A soft actor critic (SAC) embraces exploration and is data-efficient,                             but can lack stability.\n",
    "                         \n",
    "                         -A proximal policy optimization (PPO) is stable but data-hungry.\n",
    "                         \n",
    "f)Action Space:An action space is the set of all valid actions, or choices, available to an agent                as it interacts with an environment.\n",
    "\n",
    "                  -Discrete action space represents all of an agent's possible actions for each                      state in a finite set of steering angle and throttle value combinations.\n",
    "                  \n",
    "                  -Continuous action space allows the agent to select an action from a range of                      values that you define for each state\n",
    "                  \n",
    "g)Hyperparameters: They are variables that control the performance of your agent during training.                    Change the values to increase or decrease the influence of different parts of                    your model.A higher learning rate results in faster training but may reduce                      the model’s quality.\n",
    "\n",
    "h)Reward Function: It's purpose is to encourage the agent to reach its goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a8769",
   "metadata": {},
   "source": [
    "i)exploration versus exploitation: When a car first starts out, it explores by wandering in                                          random directions.This experience helps it become more                                            confident about the actions it chooses. Exploitation means the                                    car begins to exploit or use information from previous                                            experiences to help it reach its goal. Different training                                        algorithms utilize exploration and exploitation differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89275479",
   "metadata": {},
   "source": [
    "j)reward graph:While training your car in the AWS DeepRacer console, your training metrics are                  displayed on a reward graph.Plotting the total reward from each episode allows you                to see how the model performs over time. The more reward your car gets, the better                your model performs.\n",
    "\n",
    "k)AWS DeepRacer:AWS DeepRacer is a combination of a physical car and a virtual simulator in the                   AWS Console, the AWS DeepRacer League, and community races.An AWS DeepRacer                       device is not required to start learning ,you can start now in the AWS console.                   The 3D simulator in the AWS console is where training and evaluation take place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d810474",
   "metadata": {},
   "source": [
    "# Demo: Reinforcement Learning with AWS DeepRacer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce9ccd",
   "metadata": {},
   "source": [
    "To get you started with AWS DeepRacer, you receive 10 free hours to train or evaluate models and 5GB of free storage during your first month. This offer is valid for 30 days after you have used the service for the first time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c357e439",
   "metadata": {},
   "source": [
    "m)AWS DeepRacer: An autonomous race car designed to test reinforcement learning models by racing                  on a physical track\n",
    "\n",
    "n)AWS DeepComposer: A composing device powered by generative AI that creates a melody that                           transforms into a completely original song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea9d52",
   "metadata": {},
   "source": [
    "# Generative AI with AWS DeepComposer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8f54e",
   "metadata": {},
   "source": [
    "You will need a music track to get started. There are several ways to do it. You can record your own using the AWS keyboard device or the virtual keyboard provided in the console. Or you can input a MIDI file or choose a provided music track.\n",
    "\n",
    "Once the music track is inputted, choose \"Continue\" to create a model. The models you can choose are AR-CNN, GAN, and transformers. Each of them has a slightly different function. After choosing a model, you can then adjust the parameters used to train the model.\n",
    "\n",
    "Once you are done with model creation, you can select \"Continue\" to listen and improve your output melody. To edit the melody, you can either drag or extend notes directly on the piano roll or adjust the model parameters and train it again. Keep tuning your melody until you are happy with it then click \"Continue\" to finish the composition.\n",
    "\n",
    "If you want to enhance your music further with another generative model, you can do it too. Simply choose a model under the \"Next step\" section and create a new model to enhance your music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23391f8",
   "metadata": {},
   "source": [
    "Steps to follow:\n",
    "\n",
    "1.Open the AWS DeepComposer console.\n",
    "\n",
    "2.In the navigation pane, choose Music studio, then choose Start composing.\n",
    "  On the Input track page, record a melody using the virtual keyboard, import a MIDI file, or       choose an input track. On the ML technique page, choose AR-CNN. On the Inference output page,     you can do the following. \n",
    "  \n",
    "3.Change the AR-CNN parameters, choose Enhance again, and then choose Play to hear how your track    has changed. Repeat until you like the outcome.\n",
    "\n",
    "4.Choose Edit melody to modify and change the notes that were added during inference.\n",
    "\n",
    "5.Choose Continue to finish creating your composition.\n",
    "\n",
    "You can then choose Share composition, Register, or Sign in to Soundcloud and submit to the \"Melody-Go-Round\" competition. Participation in the competition is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5772c0",
   "metadata": {},
   "source": [
    "Glossary:\n",
    "\n",
    "Action: For every state, an agent needs to take an action toward achieving its goal.\n",
    "\n",
    "Agent: The piece of software you are training is called an agent. It makes decisions in an              environment to reach a goal.\n",
    "\n",
    "Discriminator: A neural network trained to differentiate between real and synthetic data.\n",
    "\n",
    "Discriminator loss: Evaluates how well the discriminator differentiates between real and fake                         data.\n",
    "\n",
    "Edit event: When a note is either added or removed from your input track during inference.\n",
    "\n",
    "Environment: The environment is the surrounding area within which the agent interacts.\n",
    "\n",
    "Exploration versus exploitation: An agent should exploit known information from previous                                          experiences to achieve higher cumulative rewards, but it also                                    needs to explore to gain new experiences that can be used in                                      choosing the best actions in the future.\n",
    "\n",
    "Generator: A neural network that learns to create new data resembling the source data on which it            was trained.\n",
    "\n",
    "Generator loss: Measures how far the output data deviates from the real data present in the                       training dataset.\n",
    "\n",
    "Hidden layer: A layer that occurs between the output and input layers. Hidden layers are tailored               to a specific task.\n",
    "\n",
    "Input layer: The first layer in a neural network. This layer receives all data that passes                    through the neural network.\n",
    "\n",
    "Output layer: The last layer in a neural network. This layer is where the predictions are                       generated based on the information captured in the hidden layers.\n",
    "\n",
    "Piano roll: A two-dimensional piano roll matrix that represents input tracks. Time is on the                 horizontal axis and pitch is on the vertical axis.\n",
    "\n",
    "Reward: Feedback is given to an agent for each action it takes in a given state. This feedback is         a numerical reward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
